{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crypto_Technical_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3a_qJPLgA07L"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn9pquOj_xpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "87ce15d3-1dac-4080-8004-7d3fcab38c08"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEi-veir_9vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_pFMm8wAMkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(file_name):\n",
        "  df = pd.read_csv(f'/content/drive/My Drive/DeepLearning/crypto_data/{file_name}.csv', names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
        "  df.set_index('time', inplace=True)\n",
        "  return df "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dowo5LcvPbdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_names = ['BCH-USD', 'BTC-USD', 'ETH-USD', 'LTC-USD']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpH1VQmtPC3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bch_df = read_data(file_names[0])\n",
        "btc_df = read_data(file_names[1])\n",
        "eth_df = read_data(file_names[2])\n",
        "ltc_df = read_data(file_names[3])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZc48HaCAVP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ecab673d-d534-43aa-8e22-5ab6114b8623"
      },
      "source": [
        "btc_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1528968660</th>\n",
              "      <td>6489.549805</td>\n",
              "      <td>6489.560059</td>\n",
              "      <td>6489.560059</td>\n",
              "      <td>6489.549805</td>\n",
              "      <td>0.587100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528968720</th>\n",
              "      <td>6487.370117</td>\n",
              "      <td>6489.560059</td>\n",
              "      <td>6489.549805</td>\n",
              "      <td>6487.379883</td>\n",
              "      <td>7.706374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528968780</th>\n",
              "      <td>6479.410156</td>\n",
              "      <td>6487.370117</td>\n",
              "      <td>6487.370117</td>\n",
              "      <td>6479.410156</td>\n",
              "      <td>3.088252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528968840</th>\n",
              "      <td>6479.410156</td>\n",
              "      <td>6479.419922</td>\n",
              "      <td>6479.419922</td>\n",
              "      <td>6479.410156</td>\n",
              "      <td>1.404100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528968900</th>\n",
              "      <td>6475.930176</td>\n",
              "      <td>6479.979980</td>\n",
              "      <td>6479.410156</td>\n",
              "      <td>6479.979980</td>\n",
              "      <td>0.753000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    low         high         open        close    volume\n",
              "time                                                                    \n",
              "1528968660  6489.549805  6489.560059  6489.560059  6489.549805  0.587100\n",
              "1528968720  6487.370117  6489.560059  6489.549805  6487.379883  7.706374\n",
              "1528968780  6479.410156  6487.370117  6487.370117  6479.410156  3.088252\n",
              "1528968840  6479.410156  6479.419922  6479.419922  6479.410156  1.404100\n",
              "1528968900  6475.930176  6479.979980  6479.410156  6479.979980  0.753000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSK1ryGyRneA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def join_df(main_df, input_df, crypto_name):\n",
        "  \n",
        "  input_df.rename(columns={'close': f'{crypto_name}_close', 'volume': f'{crypto_name}_volume'}, inplace=True)\n",
        "  input_df = input_df[[f'{crypto_name}_close', f'{crypto_name}_volume']]\n",
        "\n",
        "  if len(main_df) == 0:\n",
        "    main_df = input_df\n",
        "  else:\n",
        "    main_df = main_df.join(input_df)\n",
        "\n",
        "  return main_df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5oc7ZV0Tzzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all4_df = pd.DataFrame()\n",
        "\n",
        "all4_df = join_df(all4_df, bch_df, 'BCH')\n",
        "all4_df = join_df(all4_df, btc_df, 'BTC')\n",
        "all4_df = join_df(all4_df, eth_df, 'ETH')\n",
        "all4_df = join_df(all4_df, ltc_df, 'LTC')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PcZLiOyVhQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all4_df.fillna(method=\"ffill\", inplace=True)\n",
        "all4_df.dropna(inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUQpSjjEVtOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "47e4684f-c10a-4af5-84c7-13616e65b009"
      },
      "source": [
        "all4_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BCH_close</th>\n",
              "      <th>BCH_volume</th>\n",
              "      <th>BTC_close</th>\n",
              "      <th>BTC_volume</th>\n",
              "      <th>ETH_close</th>\n",
              "      <th>ETH_volume</th>\n",
              "      <th>LTC_close</th>\n",
              "      <th>LTC_volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1528968720</th>\n",
              "      <td>870.859985</td>\n",
              "      <td>26.856577</td>\n",
              "      <td>6487.379883</td>\n",
              "      <td>7.706374</td>\n",
              "      <td>486.01001</td>\n",
              "      <td>26.019083</td>\n",
              "      <td>96.660004</td>\n",
              "      <td>314.387024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528968780</th>\n",
              "      <td>870.099976</td>\n",
              "      <td>1.124300</td>\n",
              "      <td>6479.410156</td>\n",
              "      <td>3.088252</td>\n",
              "      <td>486.00000</td>\n",
              "      <td>8.449400</td>\n",
              "      <td>96.570000</td>\n",
              "      <td>77.129799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528968840</th>\n",
              "      <td>870.789978</td>\n",
              "      <td>1.749862</td>\n",
              "      <td>6479.410156</td>\n",
              "      <td>1.404100</td>\n",
              "      <td>485.75000</td>\n",
              "      <td>26.994646</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>7.216067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528968900</th>\n",
              "      <td>870.000000</td>\n",
              "      <td>1.680500</td>\n",
              "      <td>6479.979980</td>\n",
              "      <td>0.753000</td>\n",
              "      <td>486.00000</td>\n",
              "      <td>77.355759</td>\n",
              "      <td>96.389999</td>\n",
              "      <td>524.539978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528968960</th>\n",
              "      <td>869.989990</td>\n",
              "      <td>1.669014</td>\n",
              "      <td>6480.000000</td>\n",
              "      <td>1.490900</td>\n",
              "      <td>486.00000</td>\n",
              "      <td>7.503300</td>\n",
              "      <td>96.519997</td>\n",
              "      <td>16.991997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             BCH_close  BCH_volume  ...  LTC_close  LTC_volume\n",
              "time                                ...                       \n",
              "1528968720  870.859985   26.856577  ...  96.660004  314.387024\n",
              "1528968780  870.099976    1.124300  ...  96.570000   77.129799\n",
              "1528968840  870.789978    1.749862  ...  96.500000    7.216067\n",
              "1528968900  870.000000    1.680500  ...  96.389999  524.539978\n",
              "1528968960  869.989990    1.669014  ...  96.519997   16.991997\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAWEf8Dq3rv5",
        "colab_type": "text"
      },
      "source": [
        "### Technical Indicators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8O1jB2CAac_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def technical_indicators(dataset):\n",
        "\n",
        "    adjClose = dataset['LTC_close']\n",
        "\n",
        "    # Create 7 and 21 days Moving Average\n",
        "    dataset['ma7'] = adjClose.rolling(window=7).mean()\n",
        "    dataset['ma21'] = adjClose.rolling(window=21).mean()\n",
        "    \n",
        "    # Create MACD\n",
        "    dataset['26ema'] = adjClose.ewm(span=26).mean()\n",
        "    dataset['12ema'] = adjClose.ewm(span=12).mean()\n",
        "    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n",
        "\n",
        "    # Create Bollinger Bands\n",
        "    dataset['20sd'] = adjClose.rolling(window=20,center=False).std() \n",
        "    dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)\n",
        "    dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)\n",
        "    \n",
        "    # Create Exponential moving average\n",
        "    # dataset['ema'] = adjClose.ewm(com=0.5).mean()\n",
        "    \n",
        "    # # Create RSI\n",
        "    # delta = adjClose.diff()\n",
        "    # delta = delta[1:] \n",
        "\n",
        "    # up, down = delta.copy(), delta.copy()\n",
        "    # up[up < 0] = 0\n",
        "    # down[down > 0] = 0\n",
        "\n",
        "    # # Calculate the SMA\n",
        "    # roll_up = up.rolling(14).mean()\n",
        "    # roll_down = down.abs().rolling(14).mean()\n",
        "\n",
        "    # # Calculate the RSI based on SMA\n",
        "    # RS = roll_up / roll_down\n",
        "    # dataset['RSI'] = 100.0 - (100.0 / (1.0 + RS))\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWyXpiWUAe94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all4_df = technical_indicators(all4_df)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qO9j84oAhMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "d7e722e6-78ce-4c6b-aece-aa638c625f42"
      },
      "source": [
        "# Remove the first 20 values in order to have no NaN\n",
        "all4_df = all4_df[20:]\n",
        "all4_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BCH_close</th>\n",
              "      <th>BCH_volume</th>\n",
              "      <th>BTC_close</th>\n",
              "      <th>BTC_volume</th>\n",
              "      <th>ETH_close</th>\n",
              "      <th>ETH_volume</th>\n",
              "      <th>LTC_close</th>\n",
              "      <th>LTC_volume</th>\n",
              "      <th>ma7</th>\n",
              "      <th>ma21</th>\n",
              "      <th>26ema</th>\n",
              "      <th>12ema</th>\n",
              "      <th>MACD</th>\n",
              "      <th>20sd</th>\n",
              "      <th>upper_band</th>\n",
              "      <th>lower_band</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1528969920</th>\n",
              "      <td>873.650024</td>\n",
              "      <td>1.198600</td>\n",
              "      <td>6486.359863</td>\n",
              "      <td>1.065600</td>\n",
              "      <td>488.00000</td>\n",
              "      <td>101.905365</td>\n",
              "      <td>96.629997</td>\n",
              "      <td>65.206299</td>\n",
              "      <td>96.518570</td>\n",
              "      <td>96.478571</td>\n",
              "      <td>96.487900</td>\n",
              "      <td>96.508591</td>\n",
              "      <td>0.020691</td>\n",
              "      <td>0.075913</td>\n",
              "      <td>96.630396</td>\n",
              "      <td>96.326746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528969980</th>\n",
              "      <td>873.859985</td>\n",
              "      <td>1.293300</td>\n",
              "      <td>6487.259766</td>\n",
              "      <td>0.602759</td>\n",
              "      <td>487.98999</td>\n",
              "      <td>303.575714</td>\n",
              "      <td>96.599998</td>\n",
              "      <td>206.481979</td>\n",
              "      <td>96.547141</td>\n",
              "      <td>96.475714</td>\n",
              "      <td>96.498075</td>\n",
              "      <td>96.523019</td>\n",
              "      <td>0.024944</td>\n",
              "      <td>0.078263</td>\n",
              "      <td>96.632239</td>\n",
              "      <td>96.319189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528970040</th>\n",
              "      <td>873.750000</td>\n",
              "      <td>7.357900</td>\n",
              "      <td>6487.270020</td>\n",
              "      <td>0.427600</td>\n",
              "      <td>488.00000</td>\n",
              "      <td>20.277039</td>\n",
              "      <td>96.639999</td>\n",
              "      <td>35.712299</td>\n",
              "      <td>96.578570</td>\n",
              "      <td>96.479047</td>\n",
              "      <td>96.510746</td>\n",
              "      <td>96.541411</td>\n",
              "      <td>0.030664</td>\n",
              "      <td>0.086789</td>\n",
              "      <td>96.652626</td>\n",
              "      <td>96.305468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528970100</th>\n",
              "      <td>873.309998</td>\n",
              "      <td>2.864491</td>\n",
              "      <td>6490.000000</td>\n",
              "      <td>0.516043</td>\n",
              "      <td>487.98999</td>\n",
              "      <td>20.961819</td>\n",
              "      <td>96.660004</td>\n",
              "      <td>119.928459</td>\n",
              "      <td>96.591427</td>\n",
              "      <td>96.486666</td>\n",
              "      <td>96.523872</td>\n",
              "      <td>96.559993</td>\n",
              "      <td>0.036121</td>\n",
              "      <td>0.093147</td>\n",
              "      <td>96.672961</td>\n",
              "      <td>96.300372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528970160</th>\n",
              "      <td>873.309998</td>\n",
              "      <td>0.149200</td>\n",
              "      <td>6490.000000</td>\n",
              "      <td>0.742156</td>\n",
              "      <td>488.00000</td>\n",
              "      <td>19.020500</td>\n",
              "      <td>96.660004</td>\n",
              "      <td>27.055300</td>\n",
              "      <td>96.615714</td>\n",
              "      <td>96.499524</td>\n",
              "      <td>96.535680</td>\n",
              "      <td>96.575619</td>\n",
              "      <td>0.039939</td>\n",
              "      <td>0.100382</td>\n",
              "      <td>96.700287</td>\n",
              "      <td>96.298760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             BCH_close  BCH_volume  ...  upper_band  lower_band\n",
              "time                                ...                        \n",
              "1528969920  873.650024    1.198600  ...   96.630396   96.326746\n",
              "1528969980  873.859985    1.293300  ...   96.632239   96.319189\n",
              "1528970040  873.750000    7.357900  ...   96.652626   96.305468\n",
              "1528970100  873.309998    2.864491  ...   96.672961   96.300372\n",
              "1528970160  873.309998    0.149200  ...   96.700287   96.298760\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqTyFRxi3-sP",
        "colab_type": "text"
      },
      "source": [
        "### Create Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E8zIfl8AkaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQ_LEQ = 30\n",
        "FORECAST_PERIOD = 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHJibycVAn_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(current, future):\n",
        "    if float(future) > float(current):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgpVHrpmBbD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all4_df['Future'] = all4_df['LTC_close'].shift(-FORECAST_PERIOD)\n",
        "all4_df['Label'] = list(map(classify, all4_df['LTC_close'], all4_df['Future']))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WisHejkZBtzp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f7b455f1-c2c6-4d5e-c780-0a7e5b45ba6d"
      },
      "source": [
        "all4_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BCH_close</th>\n",
              "      <th>BCH_volume</th>\n",
              "      <th>BTC_close</th>\n",
              "      <th>BTC_volume</th>\n",
              "      <th>ETH_close</th>\n",
              "      <th>ETH_volume</th>\n",
              "      <th>LTC_close</th>\n",
              "      <th>LTC_volume</th>\n",
              "      <th>ma7</th>\n",
              "      <th>ma21</th>\n",
              "      <th>26ema</th>\n",
              "      <th>12ema</th>\n",
              "      <th>MACD</th>\n",
              "      <th>20sd</th>\n",
              "      <th>upper_band</th>\n",
              "      <th>lower_band</th>\n",
              "      <th>Future</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1528969920</th>\n",
              "      <td>873.650024</td>\n",
              "      <td>1.198600</td>\n",
              "      <td>6486.359863</td>\n",
              "      <td>1.065600</td>\n",
              "      <td>488.00000</td>\n",
              "      <td>101.905365</td>\n",
              "      <td>96.629997</td>\n",
              "      <td>65.206299</td>\n",
              "      <td>96.518570</td>\n",
              "      <td>96.478571</td>\n",
              "      <td>96.487900</td>\n",
              "      <td>96.508591</td>\n",
              "      <td>0.020691</td>\n",
              "      <td>0.075913</td>\n",
              "      <td>96.630396</td>\n",
              "      <td>96.326746</td>\n",
              "      <td>96.599998</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528969980</th>\n",
              "      <td>873.859985</td>\n",
              "      <td>1.293300</td>\n",
              "      <td>6487.259766</td>\n",
              "      <td>0.602759</td>\n",
              "      <td>487.98999</td>\n",
              "      <td>303.575714</td>\n",
              "      <td>96.599998</td>\n",
              "      <td>206.481979</td>\n",
              "      <td>96.547141</td>\n",
              "      <td>96.475714</td>\n",
              "      <td>96.498075</td>\n",
              "      <td>96.523019</td>\n",
              "      <td>0.024944</td>\n",
              "      <td>0.078263</td>\n",
              "      <td>96.632239</td>\n",
              "      <td>96.319189</td>\n",
              "      <td>96.639999</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528970040</th>\n",
              "      <td>873.750000</td>\n",
              "      <td>7.357900</td>\n",
              "      <td>6487.270020</td>\n",
              "      <td>0.427600</td>\n",
              "      <td>488.00000</td>\n",
              "      <td>20.277039</td>\n",
              "      <td>96.639999</td>\n",
              "      <td>35.712299</td>\n",
              "      <td>96.578570</td>\n",
              "      <td>96.479047</td>\n",
              "      <td>96.510746</td>\n",
              "      <td>96.541411</td>\n",
              "      <td>0.030664</td>\n",
              "      <td>0.086789</td>\n",
              "      <td>96.652626</td>\n",
              "      <td>96.305468</td>\n",
              "      <td>96.660004</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528970100</th>\n",
              "      <td>873.309998</td>\n",
              "      <td>2.864491</td>\n",
              "      <td>6490.000000</td>\n",
              "      <td>0.516043</td>\n",
              "      <td>487.98999</td>\n",
              "      <td>20.961819</td>\n",
              "      <td>96.660004</td>\n",
              "      <td>119.928459</td>\n",
              "      <td>96.591427</td>\n",
              "      <td>96.486666</td>\n",
              "      <td>96.523872</td>\n",
              "      <td>96.559993</td>\n",
              "      <td>0.036121</td>\n",
              "      <td>0.093147</td>\n",
              "      <td>96.672961</td>\n",
              "      <td>96.300372</td>\n",
              "      <td>96.660004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1528970160</th>\n",
              "      <td>873.309998</td>\n",
              "      <td>0.149200</td>\n",
              "      <td>6490.000000</td>\n",
              "      <td>0.742156</td>\n",
              "      <td>488.00000</td>\n",
              "      <td>19.020500</td>\n",
              "      <td>96.660004</td>\n",
              "      <td>27.055300</td>\n",
              "      <td>96.615714</td>\n",
              "      <td>96.499524</td>\n",
              "      <td>96.535680</td>\n",
              "      <td>96.575619</td>\n",
              "      <td>0.039939</td>\n",
              "      <td>0.100382</td>\n",
              "      <td>96.700287</td>\n",
              "      <td>96.298760</td>\n",
              "      <td>96.660004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             BCH_close  BCH_volume    BTC_close  ...  lower_band     Future  Label\n",
              "time                                             ...                              \n",
              "1528969920  873.650024    1.198600  6486.359863  ...   96.326746  96.599998      0\n",
              "1528969980  873.859985    1.293300  6487.259766  ...   96.319189  96.639999      1\n",
              "1528970040  873.750000    7.357900  6487.270020  ...   96.305468  96.660004      1\n",
              "1528970100  873.309998    2.864491  6490.000000  ...   96.300372  96.660004      0\n",
              "1528970160  873.309998    0.149200  6490.000000  ...   96.298760  96.660004      0\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a_qJPLgA07L",
        "colab_type": "text"
      },
      "source": [
        "### Creating Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rVhP4enA7_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samples = int(all4_df.shape[0] * 0.9)\n",
        "\n",
        "train_ = all4_df.iloc[:train_samples]\n",
        "validation_ = all4_df.iloc[train_samples:]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P330SARIBDVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from collections import deque\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyCeg8NYBFSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(df):\n",
        "\n",
        "    df = df.drop('Future', 1)\n",
        "\n",
        "    for col in df.columns: \n",
        "        if col != 'Label': \n",
        "            df[col] = df[col].pct_change() \n",
        "            df.dropna(inplace=True) \n",
        "            df[col] = preprocessing.scale(df[col].values)\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    sequential_data = [] \n",
        "    prev_days = deque(maxlen=SEQ_LEQ)\n",
        "\n",
        "    for i in df.values:\n",
        "      prev_days.append([n for n in i[:-1]]) \n",
        "      if len(prev_days) == SEQ_LEQ: \n",
        "        sequential_data.append([np.array(prev_days), i[-1]]) \n",
        "\n",
        "    random.shuffle(sequential_data)\n",
        "\n",
        "    ups = [] \n",
        "    downs = []  \n",
        "\n",
        "    for seq, label in sequential_data: \n",
        "        if label == 1:  \n",
        "            ups.append([seq, label]) \n",
        "        elif label == 0:\n",
        "            downs.append([seq, label]) \n",
        "\n",
        "    random.shuffle(downs) \n",
        "    random.shuffle(ups)\n",
        "\n",
        "    lower = min(len(downs), len(ups))\n",
        "\n",
        "    ups = ups[:lower]  \n",
        "    downs = downs[:lower]\n",
        "\n",
        "    sequential_data = ups+downs  \n",
        "\n",
        "    random.shuffle(sequential_data) \n",
        "\n",
        "    return sequential_data"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYl8DzRwBHcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sequences = preprocess(train_)\n",
        "test_sequences = preprocess(validation_)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phWNDb5hKSBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee74684a-9f0a-46ff-d6d9-c952e19f7ad7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2d1b99bf10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nORrq1SKVIA_",
        "colab_type": "text"
      },
      "source": [
        "### Convert to Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hVqG4OjVAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tensor_converter_e(sequence, label):\n",
        "\n",
        "  label_tensor = torch.tensor(label).to(device)\n",
        "  # label_tensor_zero = torch.zeros(1).to(device)\n",
        "  seq_tensor = torch.tensor(sequence).to(device)\n",
        "\n",
        "  return seq_tensor, label_tensor.long()\n",
        "  # return seq_tensor, label_tensor_zero.long()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQdEaVkFjC1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sequences_tensor = [tensor_converter_e(seq, label) for seq, label in train_sequences]\n",
        "test_sequences_tensor = [tensor_converter_e(seq, label) for seq, label in test_sequences]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjMj0PMgEEcQ",
        "colab_type": "text"
      },
      "source": [
        "#### Data structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKXHOOtskC_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "039b4410-b7f3-47ed-d68d-1e9b4ae30f7d"
      },
      "source": [
        "train_sequences_tensor[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 4.1923e-02, -5.6485e-03,  1.2115e-03, -6.3802e-02, -2.7308e-01,\n",
              "          -5.3773e-02,  4.0395e-03, -1.1165e-01],\n",
              "         [ 9.0364e-01, -6.1384e-03, -5.5524e-04, -6.8512e-02, -3.2858e-01,\n",
              "          -5.5306e-02,  4.0395e-03,  7.1340e-02],\n",
              "         [ 2.7958e-03, -6.0957e-03, -2.3220e-03, -2.3485e-02,  5.0330e-01,\n",
              "          -3.1415e-02,  4.0395e-03, -1.1597e-01],\n",
              "         [ 2.7958e-03, -8.9035e-04,  1.2115e-03, -7.1479e-02, -2.7312e-01,\n",
              "          -4.0592e-02,  4.0395e-03, -1.0819e-01],\n",
              "         [ 2.6361e-01, -5.9278e-03, -5.5524e-04, -6.8249e-02,  3.1730e-02,\n",
              "          -3.5427e-02,  4.0395e-03, -1.0624e-01],\n",
              "         [ 1.2933e+00, -6.1095e-03, -5.5524e-04,  1.4078e-02, -2.3603e-02,\n",
              "          -4.9716e-02,  4.0395e-03,  3.1079e-01],\n",
              "         [-3.2253e-01, -6.1302e-03, -5.5524e-04, -8.4776e-02,  3.1730e-02,\n",
              "          -4.6949e-02,  4.0395e-03, -1.2291e-01],\n",
              "         [ 1.5828e-02, -5.9514e-03, -2.3220e-03, -2.7790e-02, -2.3603e-02,\n",
              "          -5.4876e-02,  4.3260e-01, -1.1877e-01],\n",
              "         [ 2.7958e-03, -5.5855e-03, -5.5524e-04,  1.8329e-01,  2.8133e-01,\n",
              "           5.4003e-02,  4.0395e-03, -1.0058e-01],\n",
              "         [ 2.7958e-03, -6.1391e-03,  1.2115e-03, -8.4178e-02, -5.5030e-01,\n",
              "          -4.5859e-02,  4.0395e-03, -1.1806e-01],\n",
              "         [ 2.7958e-03, -6.0928e-03,  1.2658e+00,  1.6292e-02, -1.6233e-01,\n",
              "          -5.1990e-02, -1.3872e-01, -6.8407e-02],\n",
              "         [-1.0236e-02, -5.3649e-03,  8.0364e-01, -8.1544e-02,  1.4464e+00,\n",
              "          -4.0502e-02,  5.7530e-01, -9.9718e-03],\n",
              "         [ 1.5828e-02, -5.7315e-03, -2.3188e-03,  1.6579e-03, -3.0053e-01,\n",
              "          -5.6214e-02,  4.0395e-03, -1.2497e-01],\n",
              "         [-1.0236e-02, -6.0703e-03,  1.2083e-03, -6.6591e-02, -5.5004e-01,\n",
              "           2.7553e-01,  4.3215e-01,  6.4708e-02],\n",
              "         [ 2.7958e-03, -5.3801e-03, -5.5524e-04, -2.4151e-02,  2.8128e-01,\n",
              "          -5.7220e-02, -1.3863e-01, -1.2019e-01],\n",
              "         [ 1.1615e+00, -5.9558e-03,  5.2219e+00,  9.6549e-02,  3.0800e+00,\n",
              "           1.0865e+00,  2.7147e+00,  2.6654e-01],\n",
              "         [ 7.5673e-01, -6.1411e-03, -3.5689e+00, -7.7878e-02, -1.4871e+00,\n",
              "          -5.5817e-02, -1.2759e+00, -1.1227e-01],\n",
              "         [-2.8540e+00, -4.9863e-03, -1.4654e-01,  5.4018e-02, -1.6557e+00,\n",
              "          -5.5553e-02, -7.0809e-01, -8.4347e-02],\n",
              "         [-1.0252e-02, -6.0776e-03, -1.4073e+00, -8.6048e-02, -6.8880e-01,\n",
              "          -2.4793e-02, -2.2767e+00, -1.1426e-01],\n",
              "         [ 2.7958e-03, -6.0716e-03, -2.3187e-03, -9.8448e-03,  3.1824e-02,\n",
              "          -5.2042e-02,  2.8984e-01, -1.0223e-01],\n",
              "         [ 2.7958e-03, -6.1417e-03, -3.3824e-01, -7.8265e-02, -5.7844e-01,\n",
              "          -2.8158e-02,  7.1850e-01, -1.2213e-01],\n",
              "         [ 1.5844e-02, -4.8078e-03, -2.4073e-03, -7.1710e-02,  3.0940e-01,\n",
              "          -5.3255e-02, -9.9528e-01, -9.5837e-02],\n",
              "         [ 2.7958e-03, -6.1041e-03, -5.4243e-01, -6.8484e-02, -5.5085e-01,\n",
              "          -5.2227e-02, -4.2480e-01, -1.2303e-01],\n",
              "         [ 7.1972e-01, -4.4297e-03, -5.5345e-01, -6.5626e-02, -2.3726e-02,\n",
              "          -3.7443e-02,  2.9005e-01,  1.8257e-01],\n",
              "         [-6.2227e-01, -6.1400e-03, -5.5524e-04, -6.8594e-02,  3.1853e-02,\n",
              "          -5.2340e-02, -2.8187e-01, -1.2549e-01],\n",
              "         [ 2.1130e-01, -5.8004e-03, -5.5524e-04,  2.4748e-02,  4.0631e-03,\n",
              "          -2.2452e-02,  1.4707e-01, -9.3094e-02],\n",
              "         [-3.0991e-01, -5.7768e-03, -5.5524e-04, -5.1714e-02,  4.0631e-03,\n",
              "          -4.9567e-02, -1.3897e-01, -7.7010e-02],\n",
              "         [-8.8462e-02, -6.1349e-03, -2.4091e-03, -8.2552e-02,  7.8138e-01,\n",
              "          -4.9916e-02, -7.1097e-01,  1.9892e-02],\n",
              "         [ 2.7958e-03, -6.1269e-03,  1.1149e+00,  2.5279e-02,  4.0631e-03,\n",
              "          -5.5599e-02,  2.9029e-01, -1.2435e-01],\n",
              "         [ 2.7958e-03, -6.1201e-03, -5.2972e-01, -8.0659e-02, -5.5063e-01,\n",
              "          -3.2398e-03,  4.0395e-03, -1.0688e-01],\n",
              "         [-1.0254e-02, -4.5067e-03, -1.9758e-01, -6.8145e-02, -1.0229e+00,\n",
              "          -4.2438e-02,  4.0395e-03, -3.8280e-02],\n",
              "         [ 1.5846e-02, -6.0409e-03,  1.2980e-03, -3.0351e-02, -5.1480e-02,\n",
              "          -5.6787e-02,  4.0395e-03, -1.2477e-01],\n",
              "         [-7.5424e-02, -5.5519e-03, -5.5524e-04, -5.5829e-02,  4.0631e-03,\n",
              "          -2.1105e-02,  4.0395e-03, -9.8745e-03],\n",
              "         [ 2.7958e-03, -6.1202e-03,  1.8213e+00,  2.0300e-01,  4.0631e-03,\n",
              "          -3.2945e-02,  4.0395e-03, -1.0898e-01],\n",
              "         [ 2.7958e-03, -5.9139e-03, -1.5757e-01, -8.2656e-02, -1.5521e+00,\n",
              "          -4.4322e-02,  4.3325e-01, -1.2032e-01],\n",
              "         [-1.1315e+00, -4.2774e-03, -4.5720e-01, -8.3139e-02,  7.2786e-01,\n",
              "          -5.5175e-02,  1.1481e+00,  5.8887e-01],\n",
              "         [ 2.7958e-03, -6.1380e-03,  1.2961e-03, -2.7454e-03,  4.0631e-03,\n",
              "          -4.7179e-02,  1.4682e-01, -1.2525e-01],\n",
              "         [ 2.7958e-03, -6.0857e-03, -1.4504e-01,  3.4149e-02,  4.0631e-03,\n",
              "          -3.4586e-02,  4.0395e-03, -8.1520e-02],\n",
              "         [ 2.7958e-03, -6.1386e-03, -5.5524e-04, -7.6869e-02,  4.0631e-03,\n",
              "          -5.5381e-02,  4.0395e-03, -1.1249e-01],\n",
              "         [ 2.7958e-03, -2.2659e-03, -5.5524e-04, -5.8297e-02,  1.3669e+00,\n",
              "          -1.0088e-02, -1.3872e-01, -1.2127e-01],\n",
              "         [ 2.7958e-03, -6.1385e-03, -5.5524e-04, -6.1912e-02,  4.0631e-03,\n",
              "          -5.1354e-02,  1.4682e-01, -8.5861e-02],\n",
              "         [ 2.7958e-03, -4.7589e-03, -6.0068e-02, -3.5006e-02,  4.0631e-03,\n",
              "          -5.0187e-02,  4.0395e-03,  1.4924e-01],\n",
              "         [-1.4075e+00,  1.3698e-03, -5.6397e-01, -7.7293e-02,  4.0631e-03,\n",
              "          -4.1486e-02, -1.3872e-01, -1.2129e-01],\n",
              "         [ 1.1410e+00, -6.1413e-03, -3.6550e-01, -5.9378e-02,  4.0631e-03,\n",
              "          -4.6220e-02,  1.4682e-01, -1.1665e-01],\n",
              "         [ 2.7958e-03, -6.1102e-03, -5.5524e-04, -7.7867e-02, -8.5686e-01,\n",
              "           2.7936e-01, -1.3872e-01, -5.8140e-02],\n",
              "         [ 2.7958e-03, -6.1251e-03, -2.4084e-03, -4.6702e-02,  8.6582e-01,\n",
              "          -5.7195e-02, -9.9563e-01, -9.0149e-02],\n",
              "         [-1.0201e-02, -4.0440e-03,  1.2979e-03, -6.4731e-02, -8.2906e-01,\n",
              "           3.1553e-02, -5.6789e-01, -1.1806e-01],\n",
              "         [ 2.7958e-03, -6.1095e-03, -1.1807e+00,  1.6717e-01, -5.5193e-01,\n",
              "          -4.2563e-02, -1.3901e-01,  4.5208e-03],\n",
              "         [ 1.5792e-02, -5.9875e-03, -2.3220e-03, -8.0784e-02,  7.8289e-01,\n",
              "          -4.8506e-02, -9.9772e-01, -1.1647e-01],\n",
              "         [-1.0201e-02, -6.1412e-03, -2.3220e-03, -7.8585e-02, -1.3577e+00,\n",
              "          -5.0547e-02,  4.3389e-01, -4.6263e-02],\n",
              "         [ 1.5792e-02, -1.0946e-03, -5.5524e-04, -7.3225e-02, -8.0314e-01,\n",
              "          -2.2076e-02,  4.0395e-03, -1.2541e-01],\n",
              "         [ 2.7958e-03, -5.5629e-03,  1.2115e-03, -1.7895e-02, -2.3824e-02,\n",
              "          -5.6996e-02,  4.0395e-03, -1.1970e-01],\n",
              "         [ 2.7958e-03, -6.1389e-03, -5.5524e-04, -1.2059e-03,  4.0631e-03,\n",
              "          -2.3825e-02, -1.3919e-01,  2.6425e-02],\n",
              "         [-8.8654e-02, -5.5804e-03, -2.3220e-03, -8.3255e-02,  3.1951e-02,\n",
              "          -5.5525e-02,  1.4729e-01, -6.8610e-02],\n",
              "         [ 1.5872e-02, -6.1396e-03,  1.2115e-03, -5.9030e-02,  4.0631e-03,\n",
              "          -2.7641e-02,  4.0395e-03, -1.2402e-01],\n",
              "         [ 3.5556e-01,  7.7171e-03, -5.5524e-04,  4.0665e-01,  4.0631e-03,\n",
              "          -5.2737e-02,  4.0395e-03, -3.5154e-02],\n",
              "         [ 1.1781e+00, -6.1391e-03, -9.3045e-01,  1.6501e-02, -3.3023e-01,\n",
              "           1.9499e-01,  4.0395e-03, -1.2057e-01],\n",
              "         [-6.6214e-01, -6.1123e-03, -7.8045e-03, -8.6299e-02, -7.9543e-02,\n",
              "          -5.4423e-02, -1.3919e-01, -1.1138e-01],\n",
              "         [ 4.2038e-01, -6.1290e-03, -9.5726e-03, -5.4846e-02, -3.5829e-01,\n",
              "           1.0218e-01,  1.4729e-01,  1.5986e+00],\n",
              "         [-5.3197e-01, -5.9270e-03,  4.2853e-02, -1.9905e-02, -5.5364e-01,\n",
              "          -5.4939e-02,  4.0395e-03, -1.2307e-01]], device='cuda:0',\n",
              "        dtype=torch.float64), tensor(0, device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE0YPXYVVMR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24bb5cc7-e9cc-4d1c-d650-26a1b3f74419"
      },
      "source": [
        "test_sequences_tensor_labelLong[0][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR7gIrvRBUOo",
        "colab_type": "text"
      },
      "source": [
        "##### General setup for models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMlTCo4wBk8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDZa_kiefbB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h2mTq5QWt1P",
        "colab_type": "text"
      },
      "source": [
        "### CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugtDesh1Wvld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class cnn(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(cnn, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv1d(30, 64, 5)\n",
        "    self.conv2 = nn.Conv1d(64, 128, 5)\n",
        "    self.conv3 = nn.Conv1d(128, 256, 5, stride=2)\n",
        "\n",
        "    self.dropout = nn.Dropout(0)\n",
        "\n",
        "    self.fc1 = nn.Linear(512, 64)\n",
        "    self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "\n",
        "    x = F.relu(self.conv3(x))\n",
        "\n",
        "    # print(x[:5])\n",
        "    # print(len(x[0]))\n",
        "\n",
        "    # x = [yy for y in x for yy in y]\n",
        "    x = x.view(-1, x[0].shape[0]*x[0].shape[1])\n",
        "    # print(x[:5])\n",
        "    # print(len(x[0]))\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  # def predict(self, x):\n",
        "  #   logits = self.forward(x)\n",
        "  #   predictions = torch.argmax(logits, dim=-1)\n",
        "  #   return predictions"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ_SRIPNCJr1",
        "colab_type": "text"
      },
      "source": [
        "### Trainer Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKxMA4T0CGmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer():\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    model: nn.Module,\n",
        "    loss_function,\n",
        "    optimizer):\n",
        "\n",
        "    self.model = model\n",
        "    self.loss_function = loss_function\n",
        "    self.optimizer = optimizer\n",
        "\n",
        "  def train(self, train_dataset, \n",
        "            valid_dataset, \n",
        "            epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    for epoch in range(epochs):\n",
        "      print(f'Epoch {epoch+1}')\n",
        "\n",
        "      epoch_loss = 0.0\n",
        "      self.model.train()\n",
        "\n",
        "      for step, sequence in enumerate(train_dataset):\n",
        "\n",
        "        tokens = sequence[0].float()\n",
        "        labels = sequence[1]\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        predictions = self.model(tokens)\n",
        "\n",
        "        # print(f'Predictions shape is {predictions.shape}')\n",
        "        # print(predictions)\n",
        "\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        temp_loss = self.loss_function(predictions, labels)\n",
        "\n",
        "        temp_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        epoch_loss += temp_loss.tolist()\n",
        "\n",
        "        \n",
        "      avg_epoch_loss = epoch_loss / len(train_dataset)\n",
        "      train_loss += avg_epoch_loss\n",
        "\n",
        "      print(f'\\t[Epoch: {epoch+1}] Training Loss = {avg_epoch_loss}')\n",
        "      # writer.add_scalar(' Training Loss', avg_epoch_loss, epoch)\n",
        "\n",
        "      valid_loss = self.evaluate(valid_dataset)\n",
        "      \n",
        "      print(f'\\t[Epoch: {epoch+1}] Validation Loss = {valid_loss}')\n",
        "      # writer.add_scalar('Validation Loss', valid_loss, epoch)\n",
        "\n",
        "    print('Training has finished')\n",
        "    \n",
        "    avg_epoch_loss = train_loss / epochs\n",
        "\n",
        "    return avg_epoch_loss\n",
        "  \n",
        "\n",
        "  def evaluate(self, valid_dataset):\n",
        "\n",
        "    valid_loss = 0.0\n",
        "    self.model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for sequence in valid_dataset:\n",
        "        tokens = sequence[0].float()\n",
        "        labels = sequence[1]\n",
        "\n",
        "        predictions = self.model(tokens)\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        temp_loss = self.loss_function(predictions, labels)\n",
        "        # temp_loss = temp_loss.view(tokens.shape[0], -1)\n",
        "        # temp_loss = temp_loss.sum(dim=-1).mean()\n",
        "        valid_loss += temp_loss.tolist()\n",
        "      \n",
        "    return valid_loss / len(valid_dataset)\n",
        "\n",
        "\n",
        "  def predict(self, x):\n",
        "\n",
        "    self.model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        logits = self.model(x)\n",
        "        predictions = torch.argmax(logits, -1)\n",
        "        return logits, predictions"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjjeMIaAVeNH",
        "colab_type": "text"
      },
      "source": [
        "### F-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbc9ZMWGVf0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c65f40db-f705-4c34-e0e0-c28ce385c7c2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDp3wPcRVlRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f_score(labels, predictions):\n",
        "  \n",
        "  print(f'# instances: {len(labels)}')\n",
        "\n",
        "  p = precision_score(labels, predictions, average='macro')\n",
        "  r = recall_score(labels, predictions, average='macro')\n",
        "  f = f1_score(labels, predictions, average='macro')\n",
        "\n",
        "  print(f'# precision: {p:.4f}')\n",
        "  print(f'# recall: {r:.4f}')\n",
        "  print(f'# f1: {f:.4f}')\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy-InP9enKga",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XfjvMvInNu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cm_plot(test_label, pred_labels):\n",
        "\n",
        "  label=[0, 1]\n",
        "\n",
        "  cm = confusion_matrix(test_label, pred_labels, label)\n",
        "  print(cm)\n",
        "\n",
        "  sum_col_cm = np.sum(cm, axis=1, keepdims=True)\n",
        "  acc_col_cm = (cm / sum_col_cm.astype(float))\n",
        "\n",
        "  acc_col_cm = [[round(x, 4) for x in xx] for xx in acc_col_cm]\n",
        "  acc_df = pd.DataFrame(data=acc_col_cm, index=label, columns=label)\n",
        "\n",
        "  acc_df.index.name = 'ACTUAL LABELS'\n",
        "  acc_df.columns.name = 'PREDICTED LABELS'\n",
        "  fig, ax = plt.subplots(figsize=(8,6))\n",
        "  sns.heatmap(acc_df, annot=acc_col_cm, annot_kws={\"size\": 15}, fmt='', ax=ax, cmap=\"YlGnBu\")\n",
        "  plt.show()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIloIezEsAiR",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Batch Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bxdYQBdpAaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = DataLoader(train_sequences_tensor, batch_size=64)\n",
        "valid_dataset = DataLoader(test_sequences_tensor, batch_size=64)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Mv_17fGtPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "afb836e7-850d-4a2c-dea4-23fdc04bdb8b"
      },
      "source": [
        "model = cnn().cuda()\n",
        "model"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cnn(\n",
              "  (conv1): Conv1d(30, 64, kernel_size=(5,), stride=(1,))\n",
              "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
              "  (conv3): Conv1d(128, 256, kernel_size=(5,), stride=(2,))\n",
              "  (dropout): Dropout(p=0, inplace=False)\n",
              "  (fc1): Linear(in_features=512, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doEaU1fNHGuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    loss_function = nn.CrossEntropyLoss(),\n",
        "    optimizer = optim.Adam(model.parameters()),\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrICVN7C4kO-",
        "colab_type": "text"
      },
      "source": [
        "### Train CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1xmuEa8HO-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "5cddd1d6-8418-4467-b2bf-2eba62183df8"
      },
      "source": [
        "trainer.train(train_dataset, valid_dataset, 10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "\t[Epoch: 1] Training Loss = 0.6901352632613409\n",
            "\t[Epoch: 1] Validation Loss = 0.6826716638078877\n",
            "Epoch 2\n",
            "\t[Epoch: 2] Training Loss = 0.6796298723660147\n",
            "\t[Epoch: 2] Validation Loss = 0.6789348353357876\n",
            "Epoch 3\n",
            "\t[Epoch: 3] Training Loss = 0.671144709145307\n",
            "\t[Epoch: 3] Validation Loss = 0.6808250078967973\n",
            "Epoch 4\n",
            "\t[Epoch: 4] Training Loss = 0.6610916424735486\n",
            "\t[Epoch: 4] Validation Loss = 0.6884828420246348\n",
            "Epoch 5\n",
            "\t[Epoch: 5] Training Loss = 0.646309533567162\n",
            "\t[Epoch: 5] Validation Loss = 0.7022664248943329\n",
            "Epoch 6\n",
            "\t[Epoch: 6] Training Loss = 0.6276354402241994\n",
            "\t[Epoch: 6] Validation Loss = 0.72694358346509\n",
            "Epoch 7\n",
            "\t[Epoch: 7] Training Loss = 0.6042376626784264\n",
            "\t[Epoch: 7] Validation Loss = 0.7566946172246746\n",
            "Epoch 8\n",
            "\t[Epoch: 8] Training Loss = 0.5768549861868469\n",
            "\t[Epoch: 8] Validation Loss = 0.79637591102544\n",
            "Epoch 9\n",
            "\t[Epoch: 9] Training Loss = 0.5466725288217359\n",
            "\t[Epoch: 9] Validation Loss = 0.8093428290357777\n",
            "Epoch 10\n",
            "\t[Epoch: 10] Training Loss = 0.5172391326993889\n",
            "\t[Epoch: 10] Validation Loss = 0.90158030741355\n",
            "Training has finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6220950771423971"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFe9CH64hbiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'cnn_model_drop_epoch50.pth'\n",
        "path = f\"/content/drive/My Drive/DeepLearning/models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLdXf6RwiVVz",
        "colab_type": "text"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPnyubT0hPrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "test_labels = []\n",
        "\n",
        "for i in range(len(test_sequences_tensor)):\n",
        "\n",
        "  test_elem = test_sequences_tensor[i]\n",
        "  test_x, test_y = test_elem[0].float(), test_elem[1]\n",
        "      \n",
        "  logits, coded_pred = trainer.predict(test_x.unsqueeze(0))\n",
        "  predictions.append(coded_pred[0].tolist()) \n",
        "  test_labels.append(test_y.tolist())"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tl3fVk5gqgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_predictions = []\n",
        "train_labels = []\n",
        "\n",
        "for i in range(len(train_sequences_tensor)):\n",
        "\n",
        "  train_elem = train_sequences_tensor[i]\n",
        "  train_x, train_y = train_elem[0].float(), train_elem[1]\n",
        "      \n",
        "  logits, train_coded_pred = trainer.predict(train_x.unsqueeze(0))\n",
        "  train_predictions.append(train_coded_pred[0].tolist()) \n",
        "  train_labels.append(train_y.tolist())"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sxvsIEal07A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "712a5a42-6b2c-495c-adfb-96a6352e46e2"
      },
      "source": [
        "f_score(test_labels, predictions)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# instances: 6494\n",
            "# precision: 0.5319\n",
            "# recall: 0.5319\n",
            "# f1: 0.5318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4iR42iIPBHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "a9bc8ea8-3fc6-4ac7-fcaf-0cddf9b47971"
      },
      "source": [
        "cm_plot(test_labels, predictions)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1677 1570]\n",
            " [1470 1777]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4fabBxLhGX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "95be2771-8d99-45c4-ea6e-6786aea5a37f"
      },
      "source": [
        "f_score(train_labels, train_predictions)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# instances: 61768\n",
            "# precision: 0.8790\n",
            "# recall: 0.8788\n",
            "# f1: 0.8788\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}